"""
Workflow orchestration for the travel planner system.

This module implements the high-level workflow orchestration for the travel planner,
integrating the LangGraph state graph with agent interactions and event handling.
"""

import traceback
from datetime import datetime
from typing import Any, cast

from langgraph.errors import GraphInterrupt, GraphRecursionError

from travel_planner.data.models import TravelPlan, TravelQuery, UserPreferences
from travel_planner.orchestration.core.agent_registry import register_default_agents
from travel_planner.orchestration.core.graph_builder import create_planning_graph
from travel_planner.orchestration.serialization.checkpoint import save_state_checkpoint
from travel_planner.orchestration.states.planning_state import TravelPlanningState
from travel_planner.utils.logging import get_logger

logger = get_logger(__name__)


class TravelWorkflow:
    """
    Coordinates the entire travel planning workflow.

    This class is responsible for:
    1. Initializing all the agents
    2. Creating and managing the state graph
    3. Processing user queries and generating travel plans
    4. Handling interruptions and state updates
    """

    def __init__(self):
        """Initialize the travel planning workflow."""
        # Register all default agents
        register_default_agents()

        # Initialize the state graph
        self.graph = create_planning_graph()

    def process_query(
        self, query: str, preferences: UserPreferences | None = None
    ) -> TravelPlan:
        """
        Process a travel query and generate a complete travel plan.

        This method provides a synchronous interface for testing. In production,
        the async version can be used for better performance.

        Args:
            query: User's travel query
            preferences: Optional user preferences

        Returns:
            Complete travel plan
        """
        logger.info(f"Processing travel query: {query}")

        # Create initial state
        initial_state = TravelPlanningState(
            query=TravelQuery(raw_query=query),
            preferences=preferences or UserPreferences(),
            conversation_history=[{"role": "user", "content": query}],
        )

        # Execute the graph with the initial state
        try:
            # Execute the full state graph workflow
            final_state = self._execute_graph(initial_state)
            return final_state.plan
        except ValueError as e:
            # Handle validation errors (e.g., invalid state format)
            logger.error(f"Validation error in workflow: {e!s}")
            initial_state.error = f"Validation error: {e!s}"
            initial_state.conversation_history.append(
                {
                    "role": "system",
                    "content": (
                        f"Error: The travel query couldn't be processed due to "
                        f"validation issues. {e!s}"
                    ),
                }
            )
            return self._create_error_plan(e, "validation_error")
        except GraphInterrupt as e:
            # Handle interruptions (could be user-triggered or system-triggered)
            logger.info(f"Workflow interrupted: {e!s}")
            return self._handle_interruption(initial_state, e)
        except GraphRecursionError as e:
            # Handle graph recursion limit errors
            logger.error(f"Graph recursion error in workflow: {e!s}")
            initial_state.error = f"Workflow error: {e!s}"
            return self._create_error_plan(e, "graph_error")
        except Exception as e:
            # Handle any other unexpected errors
            logger.error(f"Unexpected error in travel planning workflow: {e!s}")
            logger.error(traceback.format_exc())
            initial_state.error = f"Unexpected error: {e!s}"
            return self._create_error_plan(e, "unexpected_error")

    async def process_query_async(
        self, query: str, preferences: UserPreferences | None = None
    ) -> TravelPlan:
        """
        Process a travel query and generate a complete travel plan asynchronously.

        Args:
            query: User's travel query
            preferences: Optional user preferences

        Returns:
            Complete travel plan
        """
        logger.info(f"Processing travel query asynchronously: {query}")

        # Create initial state
        initial_state = TravelPlanningState(
            query=TravelQuery(raw_query=query),
            preferences=preferences or UserPreferences(),
            conversation_history=[{"role": "user", "content": query}],
        )

        # Execute the graph with the initial state
        try:
            # Execute the full state graph workflow asynchronously
            final_state = await self._execute_graph_async(initial_state)
            return final_state.plan
        except ValueError as e:
            # Handle validation errors (e.g., invalid state format)
            logger.error(f"Validation error in async workflow: {e!s}")
            initial_state.error = f"Validation error: {e!s}"
            initial_state.conversation_history.append(
                {
                    "role": "system",
                    "content": (
                        f"Error: The travel query couldn't be processed due to "
                        f"validation issues. {e!s}"
                    ),
                }
            )
            return self._create_error_plan(e, "validation_error")
        except GraphInterrupt as e:
            # Handle interruptions (could be user-triggered or system-triggered)
            logger.info(f"Async workflow interrupted: {e!s}")
            return self._handle_interruption(initial_state, e)
        except GraphRecursionError as e:
            # Handle graph recursion limit errors
            logger.error(f"Graph recursion error in async workflow: {e!s}")
            initial_state.error = f"Workflow error: {e!s}"
            return self._create_error_plan(e, "graph_error")
        except Exception as e:
            # Handle any other unexpected errors
            logger.error(f"Unexpected error in async travel planning workflow: {e!s}")
            logger.error(traceback.format_exc())
            initial_state.error = f"Unexpected error: {e!s}"
            return self._create_error_plan(e, "unexpected_error")

    def _execute_graph(self, initial_state: TravelPlanningState) -> TravelPlanningState:
        """
        Execute the state graph with the given initial state.

        This method executes the graph workflow using LangGraph's StateGraph.

        Args:
            initial_state: Starting state for the workflow

        Returns:
            Final state after workflow completion
        """
        logger.info("Starting workflow graph execution")

        try:
            # Execute the graph with initial state
            result = self.graph.invoke(initial_state)

            # Return the final state from the result
            logger.info("Workflow execution completed successfully")
            return cast(TravelPlanningState, result)

        except Exception as e:
            logger.error(f"Error executing graph: {e!s}")
            raise

    async def _execute_graph_async(
        self, initial_state: TravelPlanningState
    ) -> TravelPlanningState:
        """
        Execute the state graph with the given initial state asynchronously.

        This method uses LangGraph's ainvoke() method to execute the workflow graph
        asynchronously, passing through all the defined nodes in the proper sequence
        based on the conditional edges and transitions defined in the state graph.

        Args:
            initial_state: Starting state for the workflow

        Returns:
            Final state after workflow completion
        """
        logger.info("Starting async workflow graph execution")

        try:
            # Execute the graph asynchronously with initial state
            result = await self.graph.ainvoke(initial_state)

            # Return the final state from the result
            logger.info("Async workflow execution completed successfully")
            return cast(TravelPlanningState, result)

        except Exception as e:
            logger.error(f"Error executing async graph: {e!s}")
            raise

    def _create_error_plan(self, error: Exception, error_type: str) -> TravelPlan:
        """
        Create a minimal travel plan with error information.

        Args:
            error: The exception that occurred
            error_type: Type of error for categorization

        Returns:
            A minimal travel plan with error information
        """
        error_plan = TravelPlan()
        error_plan.metadata = {
            "error": str(error),
            "error_type": error_type,
            "timestamp": datetime.now().isoformat(),
            "status": "failed",
        }
        error_plan.alerts = [f"Error: {error!s}"]
        return error_plan

    def _handle_interruption(
        self, state: TravelPlanningState, interrupt_error: GraphInterrupt
    ) -> TravelPlan:
        """
        Handle workflow interruption by creating a partial travel plan.

        Args:
            state: Current workflow state at interruption
            interrupt_error: The interruption error

        Returns:
            A partial travel plan with available information
        """
        # Create a plan with whatever information we have so far
        partial_plan = state.plan or TravelPlan()

        # Add interruption metadata
        partial_plan.metadata = partial_plan.metadata or {}
        partial_plan.metadata.update(
            {
                "interrupted": True,
                "interruption_reason": str(interrupt_error),
                "timestamp": datetime.now().isoformat(),
                "current_stage": str(state.current_stage),
                "resumable": True,
                "checkpoint_id": state.state_checkpoint_id
                or f"auto_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            }
        )

        # Add an alert about the interruption
        if not partial_plan.alerts:
            partial_plan.alerts = []
        partial_plan.alerts.append(
            f"Note: This plan is incomplete due to an interruption: {interrupt_error!s}"
        )

        # Store the interrupted state for possible resumption
        if not state.state_checkpoint_id:
            state.state_checkpoint_id = partial_plan.metadata["checkpoint_id"]
            self._store_interrupted_state(state)

        return partial_plan

    def _store_interrupted_state(self, state: TravelPlanningState) -> None:
        """
        Store an interrupted state for later resumption.

        Args:
            state: The state to store
        """
        # Store using the checkpoint system
        checkpoint_id = save_state_checkpoint(state)
        logger.info(f"Stored interrupted state with checkpoint ID: {checkpoint_id}")

    def resume_workflow(
        self, checkpoint_id: str, updates: dict[str, Any] | None = None
    ) -> TravelPlan:
        """
        Resume an interrupted workflow from a checkpoint.

        This is a synchronous version used for testing.

        Args:
            checkpoint_id: ID of the checkpoint to resume from
            updates: Optional updates to apply to the state

        Returns:
            Final travel plan after workflow completion
        """
        from travel_planner.orchestration.serialization.checkpoint import (
            load_state_checkpoint,
        )

        logger.info(f"Resuming workflow from checkpoint: {checkpoint_id}")

        try:
            # Load the state from the checkpoint
            state = load_state_checkpoint(checkpoint_id)

            # Apply any updates to the state
            if updates:
                for key, value in updates.items():
                    if hasattr(state, key):
                        setattr(state, key, value)

            # Mark as no longer interrupted
            state.interrupted = False
            state.interruption_reason = None

            # Add a note about resumption to conversation history
            state.conversation_history.append(
                {
                    "role": "system",
                    "content": f"Resuming workflow from stage: {state.current_stage}",
                }
            )

            # Execute the graph with the resumed state
            resumed_state = self._execute_graph(state)
            logger.info("Successfully resumed and completed workflow")
            return resumed_state.plan

        except Exception as e:
            logger.error(f"Error resuming workflow: {e!s}")
            logger.error(traceback.format_exc())
            error_plan = TravelPlan()
            error_plan.metadata = {
                "error": str(e),
                "error_type": "resume_error",
                "timestamp": datetime.now().isoformat(),
                "status": "failed",
                "checkpoint_id": checkpoint_id,
            }
            error_plan.alerts = [f"Error resuming workflow: {e!s}"]
            return error_plan

    async def resume_workflow_async(
        self, checkpoint_id: str, updates: dict[str, Any] | None = None
    ) -> TravelPlan:
        """
        Resume an interrupted workflow from a checkpoint asynchronously.

        Args:
            checkpoint_id: ID of the checkpoint to resume from
            updates: Optional updates to apply to the state

        Returns:
            Final travel plan after workflow completion
        """
        from travel_planner.orchestration.serialization.checkpoint import (
            load_state_checkpoint,
        )

        logger.info(
            f"Resuming workflow asynchronously from checkpoint: {checkpoint_id}"
        )

        try:
            # Load the state from the checkpoint
            state = load_state_checkpoint(checkpoint_id)

            # Apply any updates to the state
            if updates:
                for key, value in updates.items():
                    if hasattr(state, key):
                        setattr(state, key, value)

            # Mark as no longer interrupted
            state.interrupted = False
            state.interruption_reason = None

            # Add a note about resumption to conversation history
            state.conversation_history.append(
                {
                    "role": "system",
                    "content": f"Resuming workflow from stage: {state.current_stage}",
                }
            )

            # Execute the graph with the resumed state asynchronously
            resumed_state = await self._execute_graph_async(state)
            logger.info("Successfully resumed and completed workflow asynchronously")
            return resumed_state.plan

        except Exception as e:
            logger.error(f"Error resuming workflow asynchronously: {e!s}")
            logger.error(traceback.format_exc())
            error_plan = TravelPlan()
            error_plan.metadata = {
                "error": str(e),
                "error_type": "resume_error",
                "timestamp": datetime.now().isoformat(),
                "status": "failed",
                "checkpoint_id": checkpoint_id,
            }
            error_plan.alerts = [f"Error resuming workflow asynchronously: {e!s}"]
            return error_plan
